# ==============================================
# SECURITY NOTICE
# ==============================================
# 1. NEVER commit the actual .env file to version control
# 2. Use strong, unique API keys for each service
# 3. Regularly rotate API keys
# 4. Set appropriate rate limits to prevent abuse
# 5. Monitor API usage for unusual patterns

# Core settings
WORKSPACE_PATH=path_to_your_workspace
HOST=localhost
PORT=3000

# ==============================================
# LLM Provider API Keys
# ==============================================
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key
OPENAI_ORG_ID=your_org_id_if_applicable  # Optional: Organization ID

# Google AI Configuration
GOOGLE_API_KEY=your_google_api_key
GOOGLE_PROJECT_ID=your_project_id
GOOGLE_LOCATION=your_location  # e.g., us-central1
GOOGLE_API_QUOTA_LIMIT=100000  # Optional: Set monthly quota limit

# Anthropic Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key
ANTHROPIC_VERSION=2023-06-01  # API version header

# OpenRouter Configuration
OPENROUTER_API_KEY=your_openrouter_api_key

# ==============================================
# Security Settings
# ==============================================
# API Request Security
ENABLE_REQUEST_SIGNING=true  # Enable API request signing where supported
ENABLE_IP_WHITELIST=false  # Optional: Restrict to specific IPs
ALLOWED_IPS=127.0.0.1,your_ip_here  # Comma-separated list if IP whitelist enabled
SSL_VERIFY=true  # Verify SSL certificates for API requests

# Rate Limiting Settings
MAX_REQUESTS_PER_MINUTE=60
MAX_REQUESTS_PER_HOUR=1000
MAX_TOKENS_PER_MINUTE=100000
REQUEST_TIMEOUT=30  # seconds
RETRY_ATTEMPTS=3
RETRY_DELAY=1000  # milliseconds
RATE_LIMIT_STRATEGY=sliding_window  # sliding_window, fixed_window, or token_bucket

# ==============================================
# LLM General Settings
# ==============================================
DEFAULT_MODEL_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000
DEFAULT_TOP_P=0.95
ENABLE_CONTENT_FILTERING=true
SAFE_MODE=true  # Enable additional content filtering

# Provider API Base URLs (if needed to override defaults)
# Only change these if you're using custom endpoints or proxies
# OPENAI_API_BASE=https://api.openai.com/v1
# ANTHROPIC_API_BASE=https://api.anthropic.com
# OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# ==============================================
# Debug & Logging Settings
# ==============================================
DEBUG_MODE=false
LOG_LEVEL=info  # debug, info, warning, error
ENABLE_API_LOGGING=true  # Log API requests (sanitized)
LOG_RETENTION_DAYS=30
SANITIZE_LOGS=true  # Remove sensitive data from logs

# ==============================================
# Memory and Cache Settings
# ==============================================
MEMORY_DIR=.crewai_memories
CACHE_DIR=.crewai_cache
CACHE_ENABLED=true
MEMORY_ENABLED=true
CACHE_TTL=3600  # Time-to-live in seconds
MEMORY_ENCRYPTION_KEY=your_encryption_key  # Optional: For encrypting stored data

# ==============================================
# Agent-Specific Settings
# ==============================================
# Model Selection
CODE_AGENT_MODEL=gpt-4
TEST_AGENT_MODEL=gpt-3.5-turbo
DOCUMENTATION_AGENT_MODEL=claude-2
REVIEW_AGENT_MODEL=gemini-pro
PROMPT_AGENT_MODEL=gpt-4

# Temperature Settings
CODE_AGENT_TEMPERATURE=0.8
TEST_AGENT_TEMPERATURE=0.7
DOCUMENTATION_AGENT_TEMPERATURE=0.6
REVIEW_AGENT_TEMPERATURE=0.7
PROMPT_AGENT_TEMPERATURE=0.9

# Rate Limits Per Agent
CODE_AGENT_MAX_RPM=30
TEST_AGENT_MAX_RPM=40
DOCUMENTATION_AGENT_MAX_RPM=50
REVIEW_AGENT_MAX_RPM=30
PROMPT_AGENT_MAX_RPM=40

# ==============================================
# Custom Provider Settings
# ==============================================
# Add your custom provider settings here in format:
# CUSTOM_PROVIDER_API_KEY=your_api_key
# CUSTOM_PROVIDER_BASE_URL=your_base_url
# CUSTOM_PROVIDER_MAX_RPM=30
# CUSTOM_PROVIDER_TIMEOUT=30
